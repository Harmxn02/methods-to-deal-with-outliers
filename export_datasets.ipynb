{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **export_datasets.ipynb**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext cudf.pandas\n",
    "\n",
    "# Standard libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Scikit-learn for preprocessing, scaling, and evaluation\n",
    "from sklearn.preprocessing import RobustScaler, StandardScaler\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.metrics import classification_report\n",
    "from scipy.stats import boxcox\n",
    "\n",
    "# PyTorch\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torch import nn, optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f5642f20c90>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set random seed for reproducibility\n",
    "SEED = 287\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded successfully.\n",
      "<class 'cudf.core.dataframe.DataFrame'>\n",
      "RangeIndex: 445909 entries, 0 to 445908\n",
      "Data columns (total 79 columns):\n",
      " #   Column                        Non-Null Count   Dtype\n",
      "---  ------                        --------------   -----\n",
      " 0    Destination Port             445909 non-null  int64\n",
      " 1    Flow Duration                445909 non-null  int64\n",
      " 2    Total Fwd Packets            445909 non-null  int64\n",
      " 3    Total Backward Packets       445909 non-null  int64\n",
      " 4   Total Length of Fwd Packets   445909 non-null  int64\n",
      " 5    Total Length of Bwd Packets  445909 non-null  int64\n",
      " 6    Fwd Packet Length Max        445909 non-null  int64\n",
      " 7    Fwd Packet Length Min        445909 non-null  int64\n",
      " 8    Fwd Packet Length Mean       445909 non-null  float64\n",
      " 9    Fwd Packet Length Std        445909 non-null  float64\n",
      " 10  Bwd Packet Length Max         445909 non-null  int64\n",
      " 11   Bwd Packet Length Min        445909 non-null  int64\n",
      " 12   Bwd Packet Length Mean       445909 non-null  float64\n",
      " 13   Bwd Packet Length Std        445909 non-null  float64\n",
      " 14  Flow Bytes/s                  445708 non-null  float64\n",
      " 15   Flow Packets/s               445909 non-null  float64\n",
      " 16   Flow IAT Mean                445909 non-null  float64\n",
      " 17   Flow IAT Std                 445909 non-null  float64\n",
      " 18   Flow IAT Max                 445909 non-null  int64\n",
      " 19   Flow IAT Min                 445909 non-null  int64\n",
      " 20  Fwd IAT Total                 445909 non-null  int64\n",
      " 21   Fwd IAT Mean                 445909 non-null  float64\n",
      " 22   Fwd IAT Std                  445909 non-null  float64\n",
      " 23   Fwd IAT Max                  445909 non-null  int64\n",
      " 24   Fwd IAT Min                  445909 non-null  int64\n",
      " 25  Bwd IAT Total                 445909 non-null  int64\n",
      " 26   Bwd IAT Mean                 445909 non-null  float64\n",
      " 27   Bwd IAT Std                  445909 non-null  float64\n",
      " 28   Bwd IAT Max                  445909 non-null  int64\n",
      " 29   Bwd IAT Min                  445909 non-null  int64\n",
      " 30  Fwd PSH Flags                 445909 non-null  int64\n",
      " 31   Bwd PSH Flags                445909 non-null  int64\n",
      " 32   Fwd URG Flags                445909 non-null  int64\n",
      " 33   Bwd URG Flags                445909 non-null  int64\n",
      " 34   Fwd Header Length            445909 non-null  int64\n",
      " 35   Bwd Header Length            445909 non-null  int64\n",
      " 36  Fwd Packets/s                 445909 non-null  float64\n",
      " 37   Bwd Packets/s                445909 non-null  float64\n",
      " 38   Min Packet Length            445909 non-null  int64\n",
      " 39   Max Packet Length            445909 non-null  int64\n",
      " 40   Packet Length Mean           445909 non-null  float64\n",
      " 41   Packet Length Std            445909 non-null  float64\n",
      " 42   Packet Length Variance       445909 non-null  float64\n",
      " 43  FIN Flag Count                445909 non-null  int64\n",
      " 44   SYN Flag Count               445909 non-null  int64\n",
      " 45   RST Flag Count               445909 non-null  int64\n",
      " 46   PSH Flag Count               445909 non-null  int64\n",
      " 47   ACK Flag Count               445909 non-null  int64\n",
      " 48   URG Flag Count               445909 non-null  int64\n",
      " 49   CWE Flag Count               445909 non-null  int64\n",
      " 50   ECE Flag Count               445909 non-null  int64\n",
      " 51   Down/Up Ratio                445909 non-null  int64\n",
      " 52   Average Packet Size          445909 non-null  float64\n",
      " 53   Avg Fwd Segment Size         445909 non-null  float64\n",
      " 54   Avg Bwd Segment Size         445909 non-null  float64\n",
      " 55   Fwd Header Length.1          445909 non-null  int64\n",
      " 56  Fwd Avg Bytes/Bulk            445909 non-null  int64\n",
      " 57   Fwd Avg Packets/Bulk         445909 non-null  int64\n",
      " 58   Fwd Avg Bulk Rate            445909 non-null  int64\n",
      " 59   Bwd Avg Bytes/Bulk           445909 non-null  int64\n",
      " 60   Bwd Avg Packets/Bulk         445909 non-null  int64\n",
      " 61  Bwd Avg Bulk Rate             445909 non-null  int64\n",
      " 62  Subflow Fwd Packets           445909 non-null  int64\n",
      " 63   Subflow Fwd Bytes            445909 non-null  int64\n",
      " 64   Subflow Bwd Packets          445909 non-null  int64\n",
      " 65   Subflow Bwd Bytes            445909 non-null  int64\n",
      " 66  Init_Win_bytes_forward        445909 non-null  int64\n",
      " 67   Init_Win_bytes_backward      445909 non-null  int64\n",
      " 68   act_data_pkt_fwd             445909 non-null  int64\n",
      " 69   min_seg_size_forward         445909 non-null  int64\n",
      " 70  Active Mean                   445909 non-null  float64\n",
      " 71   Active Std                   445909 non-null  float64\n",
      " 72   Active Max                   445909 non-null  int64\n",
      " 73   Active Min                   445909 non-null  int64\n",
      " 74  Idle Mean                     445909 non-null  float64\n",
      " 75   Idle Std                     445909 non-null  float64\n",
      " 76   Idle Max                     445909 non-null  int64\n",
      " 77   Idle Min                     445909 non-null  int64\n",
      " 78   Label                        445909 non-null  object\n",
      "dtypes: float64(24), int64(54), object(1)\n",
      "memory usage: 269.7+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# DATA_PATH = \"./data/concat.csv\"\t\t\t\t\t\t\t\t# Large dataset\n",
    "DATA_PATH = \"./data/Tuesday-WorkingHours.pcap_ISCX.csv\"\t\t# Small dataset\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "\n",
    "print(\"Dataset loaded successfully.\")\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### General Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed constant features: [' Bwd PSH Flags', ' Fwd URG Flags', ' Bwd URG Flags', ' CWE Flag Count', 'Fwd Avg Bytes/Bulk', ' Fwd Avg Packets/Bulk', ' Fwd Avg Bulk Rate', ' Bwd Avg Bytes/Bulk', ' Bwd Avg Packets/Bulk', 'Bwd Avg Bulk Rate']\n"
     ]
    }
   ],
   "source": [
    "# Identify constant features (only one unique value) and drop them\n",
    "constant_features = [col for col in df.columns if df[col].nunique() == 1]\n",
    "df_filtered = df.drop(columns=constant_features)\n",
    "\n",
    "# Display removed features\n",
    "print(\"Removed constant features:\", constant_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outlier Handling Techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_percentile(series, percentile):\n",
    "    \"\"\"Computes percentile from a Pandas series\"\"\"\n",
    "    return np.percentile(series, percentile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining different outlier-handling techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def winsorize_df(df, lower_percentile=1, upper_percentile=99):\n",
    "    \"\"\"Applies Winsorization, capping extreme values at given percentiles.\"\"\"\n",
    "    df_adj = df.copy()\n",
    "    \n",
    "    for col in df.select_dtypes(include=[np.number]).columns:\n",
    "        lower_limit = get_percentile(df[col], lower_percentile)\n",
    "        upper_limit = get_percentile(df[col], upper_percentile)\n",
    "        df_adj[col] = df[col].clip(lower=lower_limit, upper=upper_limit)\n",
    "    \n",
    "    print(\"âœ… (1/8) Winsorization complete.\")\n",
    "    return df_adj\n",
    "\n",
    "def trim_outliers_df(df, lower_percentile=1, upper_percentile=99):\n",
    "\t\"\"\"Removes rows where numerical features exceed given percentiles.\"\"\"\n",
    "\tdf_adj = df.copy()\n",
    "\tinitial_size = len(df_adj)\n",
    "\t\n",
    "\tfor col in df.select_dtypes(include=[np.number]).columns:\n",
    "\t\tlower_limit = get_percentile(df[col], lower_percentile)\n",
    "\t\tupper_limit = get_percentile(df[col], upper_percentile)\n",
    "\t\tdf_adj = df_adj[(df_adj[col] >= lower_limit) & (df_adj[col] <= upper_limit)]\n",
    "\t\n",
    "\tprint(\"âœ… (2/8) Outlier trimming complete. Kept {:.2f}% of the data.\".format(len(df_adj) / initial_size * 100))\n",
    "\treturn df_adj\n",
    "\n",
    "def log_transform_df(df):\n",
    "    \"\"\"Applies log(1+x) transformation to numerical columns to reduce skew.\"\"\"\n",
    "    df_adj = df.copy()\n",
    "    \n",
    "    for col in df.select_dtypes(include=[np.number]).columns:\n",
    "        df_adj[col] = np.log1p(df[col])\n",
    "    \n",
    "    print(\"âœ… (3/8) Log transformation complete.\")\n",
    "    return df_adj\n",
    "\n",
    "def boxcox_transform_df(df):\n",
    "    \"\"\"Applies Box-Cox transformation to positive numerical columns.\"\"\"\n",
    "    df_adj = df.copy()\n",
    "    \n",
    "    for col in df.select_dtypes(include=[np.number]).columns:\n",
    "        if (df[col] > 0).all():  # Box-Cox requires strictly positive values\n",
    "            df_adj[col], _ = boxcox(df[col] + 1e-5)  # Small shift to avoid zero\n",
    "    \n",
    "    print(\"âœ… (4/8) Box-Cox transformation complete.\")\n",
    "    return df_adj\n",
    "\n",
    "def robust_scaler_df(df):\n",
    "    \"\"\"Applies RobustScaler to normalize numerical features while being resistant to outliers.\"\"\"\n",
    "    df_adj = df.copy()\n",
    "    scaler = RobustScaler()\n",
    "    num_cols = df.select_dtypes(include=[np.number]).columns\n",
    "    \n",
    "    # Handle infinite values & NaNs before scaling\n",
    "    df_adj[num_cols] = df_adj[num_cols].replace([np.inf, -np.inf], np.nan)\n",
    "    df_adj[num_cols] = df_adj[num_cols].fillna(df_adj[num_cols].median())\n",
    "    \n",
    "    # Apply RobustScaler to numerical columns\n",
    "    df_adj[num_cols] = scaler.fit_transform(df_adj[num_cols])\n",
    "    \n",
    "    print(\"âœ… (5/8) Robust scaling complete.\")\n",
    "    return df_adj\n",
    "\n",
    "def iqr_filter_df(df, threshold=1.5):\n",
    "\t\"\"\"Removes outliers using the IQR method with a relaxed threshold.\"\"\"\n",
    "\tdf_adj = df.copy()\n",
    "\tinitial_size = len(df_adj)\n",
    "\t\n",
    "\tfor col in df.select_dtypes(include=[np.number]).columns:\n",
    "\t\tQ1 = get_percentile(df[col], 25)\n",
    "\t\tQ3 = get_percentile(df[col], 75)\n",
    "\t\tIQR = Q3 - Q1\n",
    "\t\tlower_bound = Q1 - threshold * IQR\n",
    "\t\tupper_bound = Q3 + threshold * IQR\n",
    "\t\tdf_adj = df_adj[(df_adj[col] >= lower_bound) & (df_adj[col] <= upper_bound)]\n",
    "\t\n",
    "\tprint(\"âœ… (6/8) IQR filtering complete. Kept {:.2f}% of the data.\".format(len(df_adj) / initial_size * 100))\n",
    "\treturn df_adj\n",
    "\n",
    "def isolation_forest_df(df, contamination=0.01):\n",
    "    \"\"\"Removes outliers using an Isolation Forest model.\"\"\"\n",
    "    df_adj = df.copy()\n",
    "    num_cols = df.select_dtypes(include=[np.number]).columns\n",
    "    iso_forest = IsolationForest(contamination=contamination, random_state=42)\n",
    "    outliers = iso_forest.fit_predict(df[num_cols])\n",
    "    df_adj = df_adj[outliers == 1]  # Keep only inliers\n",
    "    \n",
    "    print(\"âœ… (7/8) Isolation Forest filtering complete.\")\n",
    "    return df_adj\n",
    "\n",
    "def median_impute_outliers_df(df, lower_percentile=1, upper_percentile=99):\n",
    "    \"\"\"Replaces outliers beyond percentiles with the column median.\"\"\"\n",
    "    df_adj = df.copy()\n",
    "    \n",
    "    for col in df.select_dtypes(include=[np.number]).columns:\n",
    "        lower_limit = get_percentile(df[col], lower_percentile)\n",
    "        upper_limit = get_percentile(df[col], upper_percentile)\n",
    "        median_value = df[col].median()\n",
    "        df_adj[col] = df[col].where((df[col] >= lower_limit) & (df[col] <= upper_limit), median_value)\n",
    "    \n",
    "    print(\"âœ… (8/8) Median imputation complete.\")\n",
    "    return df_adj\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applying different outlier-handling techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… (1/8) Winsorization complete.\n",
      "âœ… (2/8) Outlier trimming complete. Kept 0.00% of the data.\n",
      "âœ… (3/8) Log transformation complete.\n",
      "âœ… (4/8) Box-Cox transformation complete.\n",
      "âœ… (5/8) Robust scaling complete.\n",
      "âœ… (6/8) IQR filtering complete. Kept 0.00% of the data.\n",
      "âœ… (7/8) Isolation Forest filtering complete.\n",
      "âœ… (8/8) Median imputation complete.\n"
     ]
    }
   ],
   "source": [
    "df_winsorized = winsorize_df(df)\n",
    "df_trimmed = trim_outliers_df(df)\n",
    "df_log_transformed = log_transform_df(df)\n",
    "df_boxcox_transformed = boxcox_transform_df(df)\n",
    "df_robust_scaled = robust_scaler_df(df)\n",
    "df_iqr_filtered = iqr_filter_df(df)\n",
    "df_isolation_forest = isolation_forest_df(df)\n",
    "df_median_imputed = median_impute_outliers_df(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe_dictionary = {\n",
    "\t\"Windorized\": df_winsorized,\n",
    "\t\"Trimmed\": df_trimmed,\n",
    "\t\"Log-transformed\": df_log_transformed,\n",
    "\t\"Box-Cox transformed\": df_boxcox_transformed,\n",
    "\t\"Robust-scaled\": df_robust_scaled,\n",
    "\t\"IQR-filtered\": df_iqr_filtered,\n",
    "\t\"Isolation Forest\": df_isolation_forest,\n",
    "\t\"Median-imputed\": df_median_imputed\n",
    "}\n",
    "\n",
    "for name, df in dataframe_dictionary.items():\n",
    "\tdf.to_csv(f\"./data/exported/Tuesday/{name}.csv\", index=False)\n",
    "\n",
    "# For some reason the `ÃŒQR-filtered` and `Trimmed` datasets are only 2 KB.\n",
    "# Those functions got rid of all the data. \n",
    "\n",
    "# We will not use those datasets for the rest of the notebook."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rapids",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
